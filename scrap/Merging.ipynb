{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of districts\n",
    "districts = ['amritsar', 'barnala', 'bathinda', 'faridkot', 'fatehgarhsahib', 'fazilka', 'ferozepur', 'gurdaspur', 'hoshiarpur', 'jalandhar', 'kapurthala', 'ludhiana', 'mansa', 'moga', 'pathankot', 'patiala', 'rupnagar', 'sahibzadaajitsinghnagar(mohali)', 'nawanshahr', 'sangrur', 'shrmukatsarsahib', 'tarntaran']\n",
    "\n",
    "# Initialize an empty list to store all weather dataframes\n",
    "weather_dfs = []\n",
    "\n",
    "# Loop through each district\n",
    "for district in districts:\n",
    "    # Load weather data for the current district\n",
    "    district_weather_data = pd.read_csv(f'./Weather/{district}/{district}_average_weather.csv')\n",
    "    \n",
    "    # Add the district column to the dataframe\n",
    "    district_weather_data.insert(0, 'District', district)\n",
    "    \n",
    "    # Append the dataframe to the list\n",
    "    weather_dfs.append(district_weather_data)\n",
    "\n",
    "# Concatenate all weather dataframes into a single dataframe\n",
    "all_weather_data = pd.concat(weather_dfs)\n",
    "\n",
    "# Save the concatenated dataframe to a CSV file\n",
    "all_weather_data.to_csv('all_districts_weather_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['District', 'Year', 'Month', 'Avg_Temp', 'Avg_Feelslike', 'Avg_Dew',\n",
       "       'Avg_Humidity', 'Avg_Precipitation', 'Avg_Precipitation_Probability',\n",
       "       'Avg_Precipitation_Coverage', 'Avg_Snowfall', 'Avg_Snow_Depth',\n",
       "       'Avg_Wind_Gust', 'Avg_Wind_Speed', 'Avg_Wind_Direction', 'Avg_Pressure',\n",
       "       'Avg_Cloud_Cover', 'Avg_Visibility', 'Avg_Solar_Radiation',\n",
       "       'Avg_Solar_Energy', 'Avg_UV_Index', 'Cases'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "all_weather_data = pd.read_csv(\"../train_data/final_merged_data.csv\")\n",
    "data = all_weather_data\n",
    "all_weather_data.describe()\n",
    "all_weather_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with low correlation with 'Cases': ['Avg_Humidity', 'Avg_Snowfall', 'Avg_Snow_Depth', 'Avg_Wind_Gust', 'Avg_Wind_Speed', 'Avg_Solar_Radiation', 'Avg_Solar_Energy', 'Avg_UV_Index']\n"
     ]
    }
   ],
   "source": [
    "# Calculate Pearson correlation coefficient manually\n",
    "def pearson_correlation(x, y):\n",
    "    n = len(x)\n",
    "    sum_x = sum(x)\n",
    "    sum_y = sum(y)\n",
    "    sum_x_sq = sum(xi * xi for xi in x)\n",
    "    sum_y_sq = sum(yi * yi for yi in y)\n",
    "    sum_xy = sum(xi * yi for xi, yi in zip(x, y))\n",
    "    numerator = n * sum_xy - sum_x * sum_y\n",
    "    denominator = ((n * sum_x_sq - sum_x ** 2) * (n * sum_y_sq - sum_y ** 2)) ** 0.5\n",
    "    if denominator == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return numerator / denominator\n",
    "\n",
    "# Columns to exclude from correlation analysis\n",
    "exclude_columns = ['District','Month', 'Year']\n",
    "\n",
    "# Calculate correlation between Cases and other variables, excluding specified columns\n",
    "correlations = {}\n",
    "y_column = 'Cases'\n",
    "for column in data:\n",
    "    if column != y_column and column not in exclude_columns:\n",
    "        try:\n",
    "            # Try converting column values to float\n",
    "            column_values = [float(value) for value in data[column]]\n",
    "            correlation = pearson_correlation(column_values, data[y_column])\n",
    "            correlations[column] = correlation\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "# Filter out columns with low correlation with 'Cases'\n",
    "threshold = 0.1  # Adjust as needed\n",
    "low_correlation_columns = [column for column, correlation in correlations.items() if abs(correlation) < threshold]\n",
    "\n",
    "# Print columns with low correlation\n",
    "print(\"Columns with low correlation with 'Cases':\", low_correlation_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load merged weather data\n",
    "merged_weather_data = pd.read_csv('./all_districts_weather_data.csv')\n",
    "\n",
    "# Round weather data to 2 decimal places\n",
    "merged_weather_data = merged_weather_data.round(2)\n",
    "\n",
    "# Load cases data\n",
    "cases_data = pd.read_csv('modified_file.csv')\n",
    "\n",
    "# Reshape cases data to have 'Year' as a single column\n",
    "cases_data = cases_data.melt(id_vars=['District', 'Month'], var_name='Year', value_name='Cases')\n",
    "\n",
    "# Convert 'Year' column in cases_data to int64\n",
    "cases_data['Year'] = cases_data['Year'].astype(int)\n",
    "\n",
    "# Merge cases data with merged weather data based on District, Month, and Year\n",
    "final_merged_data = pd.merge(merged_weather_data, cases_data, on=['District', 'Month', 'Year'])\n",
    "\n",
    "# Save the final merged data to a CSV file\n",
    "final_merged_data.to_csv('final_merged_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1008 entries, 0 to 1007\n",
      "Data columns (total 22 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   District                       1008 non-null   object \n",
      " 1   Year                           1008 non-null   int64  \n",
      " 2   Month                          1008 non-null   int64  \n",
      " 3   Avg_Temp                       1008 non-null   float64\n",
      " 4   Avg_Feelslike                  1008 non-null   float64\n",
      " 5   Avg_Dew                        1008 non-null   float64\n",
      " 6   Avg_Humidity                   1008 non-null   float64\n",
      " 7   Avg_Precipitation              1008 non-null   float64\n",
      " 8   Avg_Precipitation_Probability  1008 non-null   float64\n",
      " 9   Avg_Precipitation_Coverage     1008 non-null   float64\n",
      " 10  Avg_Snowfall                   1008 non-null   float64\n",
      " 11  Avg_Snow_Depth                 1008 non-null   float64\n",
      " 12  Avg_Wind_Gust                  1008 non-null   float64\n",
      " 13  Avg_Wind_Speed                 1008 non-null   float64\n",
      " 14  Avg_Wind_Direction             1008 non-null   float64\n",
      " 15  Avg_Pressure                   1008 non-null   float64\n",
      " 16  Avg_Cloud_Cover                1008 non-null   float64\n",
      " 17  Avg_Visibility                 821 non-null    float64\n",
      " 18  Avg_Solar_Radiation            1008 non-null   float64\n",
      " 19  Avg_Solar_Energy               1008 non-null   float64\n",
      " 20  Avg_UV_Index                   1008 non-null   float64\n",
      " 21  Cases                          1008 non-null   int64  \n",
      "dtypes: float64(18), int64(3), object(1)\n",
      "memory usage: 181.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(final_merged_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Avg_Humidity', 'Avg_Snowfall', 'Avg_Snow_Depth', 'Avg_Wind_Gust', 'Avg_Wind_Speed', 'Avg_Solar_Radiation', 'Avg_Solar_Energy', 'Avg_UV_Index', 'District', 'Cases', 'Year', 'Month']\n",
      "                      0\n",
      "0          Avg_Humidity\n",
      "1          Avg_Snowfall\n",
      "2        Avg_Snow_Depth\n",
      "3         Avg_Wind_Gust\n",
      "4        Avg_Wind_Speed\n",
      "5   Avg_Solar_Radiation\n",
      "6      Avg_Solar_Energy\n",
      "7          Avg_UV_Index\n",
      "8              District\n",
      "9                 Cases\n",
      "10                 Year\n",
      "11                Month\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.1  # Adjust as needed\n",
    "low_correlation_columns = [column for column, correlation in correlations.items() if abs(correlation) < threshold]\n",
    "\n",
    "# Add 'District', 'Cases', 'Year', and 'Month' to the list of columns to be removed\n",
    "columns_to_remove = low_correlation_columns + ['District', 'Cases', 'Year', 'Month']\n",
    "\n",
    "# Create DataFrame\n",
    "print(columns_to_remove)\n",
    "df_to_remove = pd.DataFrame(columns_to_remove)\n",
    "\n",
    "# Print DataFrame\n",
    "print(df_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 2.2\n",
      "R-squared (R2) Score: 0.0\n",
      "MAE Score: 1.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('../train_data/final_merged_data.csv')\n",
    "\n",
    "# Filter data for 'jalandhar' district\n",
    "data = df[df['District'] == 'amritsar'];\n",
    "\n",
    "# Specify columns to be removed\n",
    "columns_to_remove = ['_id','Cases', 'District', 'Year', 'Month', 'Avg_Snowfall', 'Avg_Snow_Depth', \n",
    "                    'Avg_Wind_Gust', 'Avg_Wind_Speed', 'Avg_Solar_Radiation', 'Avg_Solar_Energy', 'Avg_UV_Index']\n",
    "\n",
    "# Drop specified columns and columns with NaN values\n",
    "X = data.drop(columns_to_remove, axis=1).dropna(axis=1)\n",
    "y = data['Cases']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=10)\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Round the predicted values to nearest integers\n",
    "y_pred_r = np.round(y_pred)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred_r)\n",
    "r2 = r2_score(y_test, y_pred_r)\n",
    "mae = mean_absolute_error(y_test, y_pred_r)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R-squared (R2) Score:\", r2)\n",
    "print(\"MAE Score:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
