{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of districts\n",
    "districts = ['amritsar', 'barnala', 'bathinda', 'faridkot', 'fatehgarhsahib', 'fazilka', 'ferozepur', 'gurdaspur', 'hoshiarpur', 'jalandhar', 'kapurthala', 'ludhiana', 'mansa', 'moga', 'pathankot', 'patiala', 'rupnagar', 'sahibzadaajitsinghnagar(mohali)', 'nawanshahr', 'sangrur', 'shrmukatsarsahib', 'tarntaran']\n",
    "\n",
    "# Initialize an empty list to store all weather dataframes\n",
    "weather_dfs = []\n",
    "\n",
    "# Loop through each district\n",
    "for district in districts:\n",
    "    # Load weather data for the current district\n",
    "    district_weather_data = pd.read_csv(f'./Weather/{district}/{district}_average_weather.csv')\n",
    "    \n",
    "    # Add the district column to the dataframe\n",
    "    district_weather_data.insert(0, 'District', district)\n",
    "    \n",
    "    # Append the dataframe to the list\n",
    "    weather_dfs.append(district_weather_data)\n",
    "\n",
    "# Concatenate all weather dataframes into a single dataframe\n",
    "all_weather_data = pd.concat(weather_dfs)\n",
    "\n",
    "# Save the concatenated dataframe to a CSV file\n",
    "all_weather_data.to_csv('all_districts_weather_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load merged weather data\n",
    "merged_weather_data = pd.read_csv('all_districts_weather_data.csv')\n",
    "\n",
    "# Load cases data\n",
    "cases_data = pd.read_csv('modified_file.csv')\n",
    "\n",
    "# Reshape cases data to have 'Year' as a single column\n",
    "cases_data = cases_data.melt(id_vars=['District', 'Month'], var_name='Year', value_name='Cases')\n",
    "\n",
    "# Merge cases data with merged weather data based on District, Month, and Year\n",
    "# Convert 'Year' column in cases_data to int64\n",
    "cases_data['Year'] = cases_data['Year'].astype(int)\n",
    "\n",
    "# Merge cases data with merged weather data based on District, Month, and Year\n",
    "final_merged_data = pd.merge(merged_weather_data, cases_data, on=['District', 'Month', 'Year'])\n",
    "\n",
    "# Save the final merged data to a CSV file\n",
    "final_merged_data.to_csv('final_merged_data.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1008 entries, 0 to 1007\n",
      "Data columns (total 22 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   District                       1008 non-null   object \n",
      " 1   Year                           1008 non-null   int64  \n",
      " 2   Month                          1008 non-null   int64  \n",
      " 3   Avg_Temp                       1008 non-null   float64\n",
      " 4   Avg_Feelslike                  1008 non-null   float64\n",
      " 5   Avg_Dew                        1008 non-null   float64\n",
      " 6   Avg_Humidity                   1008 non-null   float64\n",
      " 7   Avg_Precipitation              1008 non-null   float64\n",
      " 8   Avg_Precipitation_Probability  1008 non-null   float64\n",
      " 9   Avg_Precipitation_Coverage     1008 non-null   float64\n",
      " 10  Avg_Snowfall                   1008 non-null   float64\n",
      " 11  Avg_Snow_Depth                 1008 non-null   float64\n",
      " 12  Avg_Wind_Gust                  1008 non-null   float64\n",
      " 13  Avg_Wind_Speed                 1008 non-null   float64\n",
      " 14  Avg_Wind_Direction             1008 non-null   float64\n",
      " 15  Avg_Pressure                   1008 non-null   float64\n",
      " 16  Avg_Cloud_Cover                1008 non-null   float64\n",
      " 17  Avg_Visibility                 821 non-null    float64\n",
      " 18  Avg_Solar_Radiation            1008 non-null   float64\n",
      " 19  Avg_Solar_Energy               1008 non-null   float64\n",
      " 20  Avg_UV_Index                   1008 non-null   float64\n",
      " 21  Cases                          1008 non-null   int64  \n",
      "dtypes: float64(18), int64(3), object(1)\n",
      "memory usage: 181.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(final_merged_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.3958333333333333\n",
      "R-squared (R2) Score: 0.3209233060312734\n",
      "MAE Score: 0.3541666666666667\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset\n",
    "# Assuming your dataset is stored in a CSV file named 'data.csv'\n",
    "df = pd.read_csv('../train_data/final_merged_data.csv')\n",
    "\n",
    "# Explore your data to understand its structure\n",
    "# print(data.head())  # View the first few rows\n",
    "# print(data.info())  # Summary of the dataset\n",
    "\n",
    "data = df[df['District'] == 'rupnagar']\n",
    "# Split the data into independent variables (X) and dependent variable (y)\n",
    "X = data.drop(['Cases','District','Year','Month','Avg_Visibility','Avg_Snowfall', 'Avg_Snow_Depth', 'Avg_Solar_Radiation', 'Avg_Solar_Energy', 'Avg_UV_Index'], axis=1)  # Drop the target variable column\n",
    "y = data['Cases']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train = X\n",
    "y_train = y\n",
    "X_test = X\n",
    "y_test = y\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "y_pred_r = np.round(y_pred)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred_r)\n",
    "r2 = r2_score(y_test, y_pred_r)\n",
    "mae = mean_absolute_error(y_test,y_pred_r)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R-squared (R2) Score:\", r2)\n",
    "print(\"MAE Score:\", mae)\n",
    "\n",
    "\n",
    "# Plot the predicted vs actual valuesplt.figure(figsize=(10, 6))\n",
    "# plt.scatter(data[\"Avg_Temp\"], y_pred_r, color='green', label='Predicted', marker='o')\n",
    "# plt.scatter(data[\"Avg_Temp\"], y_test, color='red', label='Actual', marker='*')\n",
    "# plt.title('Actual vs. Predicted Values')\n",
    "# plt.xlabel('Actual')\n",
    "# plt.ylabel('Predicted')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# print(y_test)\n",
    "# print((y_pred_r))\n",
    "\n",
    "#moga is the best -> amritsar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
